{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/clean/processed/train_1000.txt', sep='@@')\n",
    "df2 = pd.read_csv('data/clean/processed/train_2000.txt', sep='@@')\n",
    "df3 = pd.read_csv('data/clean/processed/train_3000.txt', sep='@@')\n",
    "df4 = pd.read_csv('data/clean/processed/train_4000.txt', sep='@@')\n",
    "df5 = pd.read_csv('data/clean/processed/train_5500.txt', sep='@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15452, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df1, df2, df3, df4, df5]\n",
    "final_df = pd.concat(frames)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    s = s.lower()\n",
    "    \n",
    "    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n",
    "    s = re.sub('\\s\\W',' ',s)\n",
    "    s = re.sub('\\W\\s',' ',s)\n",
    "    \n",
    "    # make sure we didn't introduce any double spaces\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "final_df['question'] = [normalize_text(s) for s in final_df['question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container for sentences\n",
    "headlines = np.array([headline for headline in final_df['question']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a is DF series\n",
    "onehot_encoded = pd.get_dummies(final_df['entity']).astype('float32').values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = headlines\n",
    "y = onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct_index = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n",
    "y_train, y_test = y[:train_pct_index], y[train_pct_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "vocab_size = 1200\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "\n",
    "# convert validation dataset to sequence and pad sequences\n",
    "validation_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "validation_padded = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "# categorical-cross-entropy requires labels one-hot-encoded. sparse = as ints. binary = t/f\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "num_epochs = 20\n",
    "history = model.fit(train_padded, y_train, \n",
    "                    epochs=num_epochs, verbose=1,\n",
    "                    validation_split=0.3)\n",
    "\n",
    "# predict values\n",
    "pred = model.predict(validation_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history_and_save(history, save_path):\n",
    "    \n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', c='dodgerblue', lw='2')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', c='orange', lw='2')\n",
    "    plt.title('Accuracy', loc='left', fontsize=16)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', c='dodgerblue', lw='2')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', c='orange', lw='2')\n",
    "    plt.title('Loss', loc='left', fontsize=16)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_no = '1'\n",
    "model_name = 'model_5500'\n",
    "#####\n",
    "save_path = f'images/plot_history/{model_name}/run_{run_no}.png' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_and_save(history, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "\n",
    "def plot_cm(pred):\n",
    "    \n",
    "    pred = np.round(pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    mcm = multilabel_confusion_matrix(y_test, pred)\n",
    "\n",
    "    # cm = confusion_matrix(validation_labels, pred)\n",
    "    sns.heatmap(mcm, annot=True, cbar=False, fmt='1d', cmap='Blues', ax=ax)\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_yticklabels(['DESC', 'ENTY', 'LOC', 'HUM', 'NUM', 'ABBR'])\n",
    "    ax.set_xticklabels(['DESC', 'ENTY', 'LOC', 'HUM', 'NUM', 'ABBR'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm = confusion_matrix(y_test.argmax(axis=1), pred.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm_df = pd.DataFrame(mcm,\n",
    "                     index = ['DESC', 'ENTY', 'LOC', 'HUM', 'NUM', 'ABBR'], \n",
    "                     columns = ['DESC', 'ENTY', 'LOC', 'HUM', 'NUM', 'ABBR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_cm = f'images/cm/{model_name}/run_{run_no}.png' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(mcm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.savefig(save_path_cm, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow SavedModel format => .keras\n",
    "model_file = 'models/5500'\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be used to reconstruct the model identically.\n",
    "reconstructed_model = keras.models.load_model(model_file)\n",
    "\n",
    "# Let's check:\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(validation_padded), reconstructed_model.predict(validation_padded)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
